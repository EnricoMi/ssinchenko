<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>How to estimate a PySpark DF size? | Sem Sinchenko</title>
<meta name="keywords" content="spark, pyspark">
<meta name="description" content="Sometimes it is an important question, how much memory does our DataFrame use? And there is no easy answer if you are working with PySpark. You can try to collect the data sample and run local memory profiler. You can estimate the size of the data in the source (for example, in parquet file). But we will go another way and try to analyze the logical plan of Spark from PySpark. In case when we are working with Scala Spark API we are able to work with resolved or unresolved logical plans and physical plan via a special API. But from PySpark API only string representation is available and we will work with it.">
<meta name="author" content="Sem Sinchenko">
<link rel="canonical" href="https://semyonsinchenko.gihub.io/ssinchenko/post/estimation-spark-df-size/">
<link crossorigin="anonymous" href="/ssinchenko/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://semyonsinchenko.gihub.io/ssinchenko/images/fav/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://semyonsinchenko.gihub.io/ssinchenko/images/fav/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://semyonsinchenko.gihub.io/ssinchenko/images/fav/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://semyonsinchenko.gihub.io/ssinchenko/images/fav/apple-touch-icon.png">
<link rel="mask-icon" href="https://semyonsinchenko.gihub.io/ssinchenko/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://semyonsinchenko.gihub.io/ssinchenko/post/estimation-spark-df-size/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="How to estimate a PySpark DF size?" />
<meta property="og:description" content="Sometimes it is an important question, how much memory does our DataFrame use? And there is no easy answer if you are working with PySpark. You can try to collect the data sample and run local memory profiler. You can estimate the size of the data in the source (for example, in parquet file). But we will go another way and try to analyze the logical plan of Spark from PySpark. In case when we are working with Scala Spark API we are able to work with resolved or unresolved logical plans and physical plan via a special API. But from PySpark API only string representation is available and we will work with it." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://semyonsinchenko.gihub.io/ssinchenko/post/estimation-spark-df-size/" />
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/f/f3/Apache_Spark_logo.svg" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2023-11-23T23:27:05+02:00" />
<meta property="article:modified_time" content="2023-11-23T23:27:05+02:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://upload.wikimedia.org/wikipedia/commons/f/f3/Apache_Spark_logo.svg" />
<meta name="twitter:title" content="How to estimate a PySpark DF size?"/>
<meta name="twitter:description" content="Sometimes it is an important question, how much memory does our DataFrame use? And there is no easy answer if you are working with PySpark. You can try to collect the data sample and run local memory profiler. You can estimate the size of the data in the source (for example, in parquet file). But we will go another way and try to analyze the logical plan of Spark from PySpark. In case when we are working with Scala Spark API we are able to work with resolved or unresolved logical plans and physical plan via a special API. But from PySpark API only string representation is available and we will work with it."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://semyonsinchenko.gihub.io/ssinchenko/post/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "How to estimate a PySpark DF size?",
      "item": "https://semyonsinchenko.gihub.io/ssinchenko/post/estimation-spark-df-size/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "How to estimate a PySpark DF size?",
  "name": "How to estimate a PySpark DF size?",
  "description": "Sometimes it is an important question, how much memory does our DataFrame use? And there is no easy answer if you are working with PySpark. You can try to collect the data sample and run local memory profiler. You can estimate the size of the data in the source (for example, in parquet file). But we will go another way and try to analyze the logical plan of Spark from PySpark. In case when we are working with Scala Spark API we are able to work with resolved or unresolved logical plans and physical plan via a special API. But from PySpark API only string representation is available and we will work with it.",
  "keywords": [
    "spark", "pyspark"
  ],
  "articleBody": " How to estimate a PySpark DataFrame size? Sometimes it is an important question, how much memory does our DataFrame use? And there is no easy answer if you are working with PySpark. You can try to collect the data sample and run local memory profiler. You can estimate the size of the data in the source (for example, in parquet file). But we will go another way and try to analyze the logical plan of Spark from PySpark. In case when we are working with Scala Spark API we are able to work with resolved or unresolved logical plans and physical plan via a special API. But from PySpark API only string representation is available and we will work with it.\nGetting Logical Plan There are two ways to get the logical plan: the first one is via SQL command EXPLAIN and the second one is via df.explain. We will use the second one just to skip the process of creating a temporary view from a DataFrame. df.explain does not provide and API to get a string representation of the plan, it is sent to standard output instead. We need to redirect standard output to get the plan:\nimport contextlib import io with contextlib.redirect_stdout(io.StringIO()) as stdout: df.explain(mode=\"cost\") logical_plan = stdout.getvalue().split(\"\\n\") Here we used the argument mode=\"extended\". Based on documentation, this argument means:\ncost: Print a logical plan and statistics if they are available.\nSo, we will get all the available statistics, include the estimated size of the DataFrame that we are looking for.\nLet's see what the plan looks like. But first we need some data frames of different sizes for our experiments. I was working on the project to rewrite h2o db benchamrk generation from R to Rust (it is now part of the farsante repository) and had some CSV benchmark datasets of different sizes, from a few Kb to a few Gb. I can use them for our experiments:\nfrom pyspark.sql import SparkSession spark = SparkSession.builder.master(\"local[*]\").getOrCreate() medium_data = spark.read.csv(\"/home/sem/github/farsante/h2o-data-rust/G1_1e8_1e8_10_5.csv\") small_data = spark.read.csv(\"/home/sem/github/farsante/h2o-data-rust/J1_1e8_1e5_5.csv\") tiny_data = spark.read.csv(\"/home/sem/github/farsante/h2o-data-rust/J1_1e8_1e2_5.csv\") And the output logical plan looks like this:\nmedium_data.explain(mode=\"cost\") == Optimized Logical Plan == Relation [_c0#17,_c1#18,_c.....,_c7#24,_c8#25] csv, Statistics(sizeInBytes=4.5 GiB) == Physical Plan == FileScan csv [_c0#17,_c1#18,_c......,_c7#24,_c8#25] Batched: false, DataFilters: [], Format: CSV, Loc... As you can see, the information we are looking for is in the first (or top) row. And it will always be there, because the logical plan is \"reversed\" and goes from the last operation to the first one, line by line. So the top line of the logical plan will always be a line representing the current state of our DataFrame.\nParsing the top line of the logical plan As you already understand, we are looking for the number from this line: Statistics(sizeInBytes=4.5 GiB). Let's use built-in Python regexps to extract this information:\nimport re pattern = r\"^.*sizeInBytes=([0-9]+\\.[0-9]+)\\s(B|KiB|MiB|GiB|TiB|EiB).*$\" Let's see on the pattern. It says:\n^.*: any amount of symbols in the beginning of the row. sizeInBytes=([0-9]+\\.[0-9]+): the number if the form of 1234.1234 exactly after the word sizeInBytes and equal sign. We create a regex-group from this number. \\s(B|KiB|MiB|GiB|TiB|EiB|): our second group which follows the first one after exactly one space symbol. .*$: any amount of symbols in the end of the row. with contextlib.redirect_stdout(io.StringIO()) as stdout: medium_data.explain(mode=\"cost\") plan = stdout.getvalue() top_line = plan.split(\"\\n\")[1] re.match(pattern, top_line).groups() Result:\n('4.5', 'GiB') Looks like it works!\nCorner case: what happens if Spark doesn't know the size? Before we finalize our code in the Python function, let's check what happens if Spark doesn't know the size of the data. This is the common case for DataFrame objects that are created from memory, not from disk.\ndata = [(i, f\"id{i}\", f\"id2{i}\", f\"id3{i}\") for i in range(1_100_000)] sdf = spark.createDataFrame( data, schema=\"struct\" ).withColumn(\"new_col\", F.col(\"c1\") * 4) with contextlib.redirect_stdout(io.StringIO()) as stdout: sdf.explain(mode=\"cost\") plan = stdout.getvalue() top_line = plan.split(\"\\n\")[1] re.match(pattern, top_line).groups() Result:\n('8.4', 'EiB') This is not what we expected, is it? An EiB is something like \\(\\simeq 10^6\\) TiB… The answer is simple: if spark cannot estimate the size, it simply returns the maximum available value (Scala Long.MaxValue). You might say this is a bug, but after reading this discussion I understood that there is no easy way to work around it on the side of Spark. So let's just catch this case on the Python side. Unfortunately, our final code with a workaround won't work if your data is really EiB in size, but I can't imagine such an amount in a single Spark Job.\nFinalized code from pyspark.sql import DataFrame def _bytes2mb(bb: float) -\u003e float: return bb / 1024 / 1024 def estimate_size_of_df(df: DataFrame, size_in_mb: bool = False) -\u003e float: \"\"\"Estimate the size in Bytes of the given DataFrame. If the size cannot be estimated return -1.0. It is possible if we failed to parse plan or, most probably, it is the case when statistics is unavailable. There is a problem that currently in the case of missing statistics spark return 8 (or 12) EiB. If your data size is really measured in EiB this function cannot help you. See https://github.com/apache/spark/pull/31817 for details. Size is returned in Bytes! This function works only in PySpark 3.0.0 or higher! :param df: DataFrame :param size_in_mb: Convert output to Mb instead of B :returns: size in bytes (or Mb if size_in_mb) \"\"\" with contextlib.redirect_stdout(io.StringIO()) as stdout: # mode argument was added in 3.0.0 df.explain(mode=\"cost\") # Get top line of Optimized Logical Plan # The output of df.explain(mode=\"cost\") starts from the following line: # == Optimized Logical Plan == # The next line after this should contain something like: # Statistics(sizeInBytes=3.0 MiB) (untis may be different) top_line = stdout.getvalue().split(\"\\n\")[1] # We need a pattern to parse the real size and untis pattern = r\"^.*sizeInBytes=([0-9]+\\.[0-9]+)\\s(B|KiB|MiB|GiB|TiB|EiB).*$\" _match = re.search(pattern, top_line) if _match: size = float(_match.groups()[0]) units = _match.groups()[1] else: return -1 if units == \"KiB\": size *= 1024 if units == \"MiB\": size *= 1024 * 1024 if units == \"GiB\": size *= 1024 * 1024 * 1024 if units == \"TiB\": size *= 1024 * 1024 * 1024 * 1024 if units == \"EiB\": # Most probably it is the case when Statistics is unavailable # In this case spark just returns max possible value # See https://github.com/apache/spark/pull/31817 for details size = -1 if size \u003c 0: return size if size_in_mb: return _bytes2mb(size) # size in Mb return size # size in bytes Testing print(estimate_size_of_df(medium_data, size_in_mb=False)) print(estimate_size_of_df(medium_data, size_in_mb=True)) print(estimate_size_of_df(small_data, size_in_mb=True)) print(estimate_size_of_df(tiny_data, size_in_mb=False)) Result:\n4831838208.0 4608.0 3.0 1691.0 ",
  "wordCount" : "1068",
  "inLanguage": "en",
  "image":"https://upload.wikimedia.org/wikipedia/commons/f/f3/Apache_Spark_logo.svg","datePublished": "2023-11-23T23:27:05+02:00",
  "dateModified": "2023-11-23T23:27:05+02:00",
  "author":{
    "@type": "Person",
    "name": "Sem Sinchenko"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://semyonsinchenko.gihub.io/ssinchenko/post/estimation-spark-df-size/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Sem Sinchenko",
    "logo": {
      "@type": "ImageObject",
      "url": "https://semyonsinchenko.gihub.io/ssinchenko/images/fav/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://semyonsinchenko.gihub.io/ssinchenko/" accesskey="h" title="Sem Sinchenko (Alt + H)">Sem Sinchenko</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://semyonsinchenko.gihub.io/ssinchenko/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="https://semyonsinchenko.gihub.io/ssinchenko/page/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://semyonsinchenko.gihub.io/ssinchenko/page/cv/" title="CV">
                    <span>CV</span>
                </a>
            </li>
            <li>
                <a href="https://semyonsinchenko.gihub.io/ssinchenko/categories" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://semyonsinchenko.gihub.io/ssinchenko/tags" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      How to estimate a PySpark DF size?
    </h1>
    <div class="post-meta"><span title='2023-11-23 23:27:05 +0200 +0200'>November 23, 2023</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;Sem Sinchenko

</div>
  </header> 
<figure class="entry-cover"><img loading="eager" src="https://upload.wikimedia.org/wikipedia/commons/f/f3/Apache_Spark_logo.svg" alt="">
        
</figure>
  <div class="post-content">
<div id="outline-container-headline-1" class="outline-2">
<h2 id="headline-1">
How to estimate a PySpark DataFrame size?
</h2>
<div id="outline-text-headline-1" class="outline-text-2">
<p>
Sometimes it is an important question, how much memory does our <code>DataFrame</code> use? And there is no easy answer if you are working with <code>PySpark</code>. You can try to collect the data sample and run local memory profiler. You can estimate the size of the data in the source (for example, in <code>parquet</code> file). But we will go another way and try to analyze the logical plan of Spark from PySpark. In case when we are working with Scala Spark API we are able to work with resolved or unresolved logical plans and physical plan via a special API. But from PySpark API only string representation is available and we will work with it.</p>
<div id="outline-container-headline-2" class="outline-3">
<h3 id="headline-2">
Getting Logical Plan
</h3>
<div id="outline-text-headline-2" class="outline-text-3">
<p>
There are two ways to get the logical plan: the first one is via SQL command <code class="verbatim">EXPLAIN</code> and the second one is via <code class="verbatim">df.explain</code>. We will use the second one just to skip the process of creating a temporary view from a <code class="verbatim">DataFrame</code>. <code class="verbatim">df.explain</code> does not provide and API to get a string representation of the plan, it is sent to standard output instead. We need to redirect standard output to get the plan:</p>
<div class="src src-python">
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">  <span class="kn">import</span> <span class="nn">contextlib</span>
</span></span><span class="line"><span class="cl">  <span class="kn">import</span> <span class="nn">io</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">with</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">redirect_stdout</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">StringIO</span><span class="p">())</span> <span class="k">as</span> <span class="n">stdout</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="n">df</span><span class="o">.</span><span class="n">explain</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&#34;cost&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">stdout</span><span class="o">.</span><span class="n">getvalue</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span></span></span></code></pre></div>
</div>
<p>
Here we used the argument <code>mode=&#34;extended&#34;</code>. Based on <a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.explain.html#pyspark.sql.DataFrame.explain">documentation</a>, this argument means:</p>
<blockquote>
<p><code>cost</code>: Print a logical plan and statistics if they are available.</p>
</blockquote>
<p>
So, we will get all the available statistics, include the estimated size of the <code>DataFrame</code> that we are looking for.</p>
<p>
Let&#39;s see what the plan looks like. But first we need some data frames of different sizes for our experiments. I was working on the project to rewrite <a href="https://github.com/h2oai/db-benchmark/tree/master/_data">h2o db benchamrk generation</a> from <code>R</code> to <code>Rust</code> (it is now part of the <a href="https://github.com/MrPowers/farsante/tree/master/h2o-data-rust">farsante repository</a>) and had some <code>CSV</code> benchmark datasets of different sizes, from a few Kb to a few Gb. I can use them for our experiments:</p>
<div class="src src-python">
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">  <span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">master</span><span class="p">(</span><span class="s2">&#34;local[*]&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">  <span class="n">medium_data</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&#34;/home/sem/github/farsante/h2o-data-rust/G1_1e8_1e8_10_5.csv&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">small_data</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&#34;/home/sem/github/farsante/h2o-data-rust/J1_1e8_1e5_5.csv&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">tiny_data</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&#34;/home/sem/github/farsante/h2o-data-rust/J1_1e8_1e2_5.csv&#34;</span><span class="p">)</span></span></span></code></pre></div>
</div>
<p>
And the output logical plan looks like this:</p>
<div class="src src-python">
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">  <span class="n">medium_data</span><span class="o">.</span><span class="n">explain</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&#34;cost&#34;</span><span class="p">)</span></span></span></code></pre></div>
</div>
<div class="src src-shell">
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">  <span class="o">==</span> Optimized Logical <span class="nv">Plan</span> <span class="o">==</span>
</span></span><span class="line"><span class="cl">  Relation <span class="o">[</span>_c0#17,_c1#18,_c.....,_c7#24,_c8#25<span class="o">]</span> csv, Statistics<span class="o">(</span><span class="nv">sizeInBytes</span><span class="o">=</span>4.5 GiB<span class="o">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="o">==</span> Physical <span class="nv">Plan</span> <span class="o">==</span>
</span></span><span class="line"><span class="cl">  FileScan csv <span class="o">[</span>_c0#17,_c1#18,_c......,_c7#24,_c8#25<span class="o">]</span> Batched: false, DataFilters: <span class="o">[]</span>, Format: CSV, Loc...</span></span></code></pre></div>
</div>
<p>
As you can see, the information we are looking for is in the first (or top) row. And it will always be there, because the logical plan is &#34;reversed&#34; and goes from the last operation to the first one, line by line. So the top line of the logical plan will always be a line representing the current state of our <code>DataFrame</code>.</p>
</div>
</div>
<div id="outline-container-headline-3" class="outline-3">
<h3 id="headline-3">
Parsing the top line of the logical plan
</h3>
<div id="outline-text-headline-3" class="outline-text-3">
<p>
As you already understand, we are looking for the number from this line: <code>Statistics(sizeInBytes=4.5 GiB)</code>. Let&#39;s use built-in Python regexps to extract this information:</p>
<div class="src src-python">
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">  <span class="kn">import</span> <span class="nn">re</span>
</span></span><span class="line"><span class="cl">  <span class="n">pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&#34;^.*sizeInBytes=([0-9]+\.[0-9]+)\s(B|KiB|MiB|GiB|TiB|EiB).*$&#34;</span></span></span></code></pre></div>
</div>
<p>
Let&#39;s see on the pattern. It says:</p>
<ol>
<li><code>^.*</code>: any amount of symbols in the beginning of the row.</li>
<li><code>sizeInBytes=([0-9]+\.[0-9]+)</code>: the number if the form of <code class="verbatim">1234.1234</code> exactly after the word <code class="verbatim">sizeInBytes</code> and equal sign. We create a regex-group from this number.</li>
<li><code>\s(B|KiB|MiB|GiB|TiB|EiB|)</code>: our second group which follows the first one after exactly one space symbol.</li>
<li><code>.*$</code>: any amount of symbols in the end of the row.</li>
</ol>
<div class="src src-python">
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">  <span class="k">with</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">redirect_stdout</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">StringIO</span><span class="p">())</span> <span class="k">as</span> <span class="n">stdout</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="n">medium_data</span><span class="o">.</span><span class="n">explain</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&#34;cost&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">plan</span> <span class="o">=</span> <span class="n">stdout</span><span class="o">.</span><span class="n">getvalue</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">  <span class="n">top_line</span> <span class="o">=</span> <span class="n">plan</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="n">re</span><span class="o">.</span><span class="k">match</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">top_line</span><span class="p">)</span><span class="o">.</span><span class="n">groups</span><span class="p">()</span></span></span></code></pre></div>
</div>
<p>
Result:</p>
<div class="src src-shell">
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">  <span class="o">(</span><span class="s1">&#39;4.5&#39;</span>, <span class="s1">&#39;GiB&#39;</span><span class="o">)</span></span></span></code></pre></div>
</div>
<p>
Looks like it works!</p>
</div>
</div>
<div id="outline-container-headline-4" class="outline-3">
<h3 id="headline-4">
Corner case: what happens if Spark doesn&#39;t know the size?
</h3>
<div id="outline-text-headline-4" class="outline-text-3">
<p>
Before we finalize our code in the Python function, let&#39;s check what happens if Spark doesn&#39;t know the size of the data. This is the common case for <code>DataFrame</code> objects that are created from memory, not from disk.</p>
<div class="src src-python">
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">  <span class="n">data</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&#34;id</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&#34;id2</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&#34;id3</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1_100_000</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">  <span class="n">sdf</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">      <span class="n">data</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="n">schema</span><span class="o">=</span><span class="s2">&#34;struct&lt;c1:int,c2:string,c3:string,c4:string&gt;&#34;</span>
</span></span><span class="line"><span class="cl">  <span class="p">)</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&#34;new_col&#34;</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&#34;c1&#34;</span><span class="p">)</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">with</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">redirect_stdout</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">StringIO</span><span class="p">())</span> <span class="k">as</span> <span class="n">stdout</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="n">sdf</span><span class="o">.</span><span class="n">explain</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&#34;cost&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">plan</span> <span class="o">=</span> <span class="n">stdout</span><span class="o">.</span><span class="n">getvalue</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">  <span class="n">top_line</span> <span class="o">=</span> <span class="n">plan</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">re</span><span class="o">.</span><span class="k">match</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">top_line</span><span class="p">)</span><span class="o">.</span><span class="n">groups</span><span class="p">()</span></span></span></code></pre></div>
</div>
<p>
Result:</p>
<div class="src src-shell">
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">  <span class="o">(</span><span class="s1">&#39;8.4&#39;</span>, <span class="s1">&#39;EiB&#39;</span><span class="o">)</span></span></span></code></pre></div>
</div>
<p>
This is not what we expected, is it? An <code>EiB</code> is something like \(\simeq 10^6\) <code>TiB</code>… The answer is simple: if spark cannot estimate the size, it simply returns the maximum available value (Scala <code>Long.MaxValue</code>). You might say this is a bug, but after reading <a href="https://github.com/apache/spark/pull/31817">this discussion</a> I understood that there is no easy way to work around it on the side of Spark. So let&#39;s just catch this case on the Python side. Unfortunately, our final code with a workaround won&#39;t work if your data is really <code>EiB</code> in size, but I can&#39;t imagine such an amount in a single Spark Job.</p>
</div>
</div>
<div id="outline-container-headline-5" class="outline-3">
<h3 id="headline-5">
Finalized code
</h3>
<div id="outline-text-headline-5" class="outline-text-3">
<div class="src src-python">
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">  <span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">DataFrame</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">_bytes2mb</span><span class="p">(</span><span class="n">bb</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="k">return</span> <span class="n">bb</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">estimate_size_of_df</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">DataFrame</span><span class="p">,</span> <span class="n">size_in_mb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="s2">&#34;&#34;&#34;Estimate the size in Bytes of the given DataFrame.
</span></span></span><span class="line"><span class="cl"><span class="s2">      If the size cannot be estimated return -1.0. It is possible if
</span></span></span><span class="line"><span class="cl"><span class="s2">      we failed to parse plan or, most probably, it is the case when statistics
</span></span></span><span class="line"><span class="cl"><span class="s2">      is unavailable. There is a problem that currently in the case of missing
</span></span></span><span class="line"><span class="cl"><span class="s2">      statistics spark return 8 (or 12) EiB. If your data size is really measured in EiB
</span></span></span><span class="line"><span class="cl"><span class="s2">      this function cannot help you. See https://github.com/apache/spark/pull/31817
</span></span></span><span class="line"><span class="cl"><span class="s2">      for details. Size is returned in Bytes!
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">      This function works only in PySpark 3.0.0 or higher!
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">      :param df: DataFrame
</span></span></span><span class="line"><span class="cl"><span class="s2">      :param size_in_mb: Convert output to Mb instead of B
</span></span></span><span class="line"><span class="cl"><span class="s2">      :returns: size in bytes (or Mb if size_in_mb)
</span></span></span><span class="line"><span class="cl"><span class="s2">      &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">      <span class="k">with</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">redirect_stdout</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">StringIO</span><span class="p">())</span> <span class="k">as</span> <span class="n">stdout</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="c1"># mode argument was added in 3.0.0</span>
</span></span><span class="line"><span class="cl">          <span class="n">df</span><span class="o">.</span><span class="n">explain</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&#34;cost&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="c1"># Get top line of Optimized Logical Plan</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># The output of df.explain(mode=&#34;cost&#34;) starts from the following line:</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># == Optimized Logical Plan ==</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># The next line after this should contain something like:</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># Statistics(sizeInBytes=3.0 MiB) (untis may be different)</span>
</span></span><span class="line"><span class="cl">      <span class="n">top_line</span> <span class="o">=</span> <span class="n">stdout</span><span class="o">.</span><span class="n">getvalue</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="c1"># We need a pattern to parse the real size and untis</span>
</span></span><span class="line"><span class="cl">      <span class="n">pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&#34;^.*sizeInBytes=([0-9]+\.[0-9]+)\s(B|KiB|MiB|GiB|TiB|EiB).*$&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="n">_match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">top_line</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="k">if</span> <span class="n">_match</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="n">size</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">_match</span><span class="o">.</span><span class="n">groups</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">          <span class="n">units</span> <span class="o">=</span> <span class="n">_match</span><span class="o">.</span><span class="n">groups</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">      <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="k">return</span> <span class="o">-</span><span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="k">if</span> <span class="n">units</span> <span class="o">==</span> <span class="s2">&#34;KiB&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="n">size</span> <span class="o">*=</span> <span class="mi">1024</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="k">if</span> <span class="n">units</span> <span class="o">==</span> <span class="s2">&#34;MiB&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="n">size</span> <span class="o">*=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="k">if</span> <span class="n">units</span> <span class="o">==</span> <span class="s2">&#34;GiB&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="n">size</span> <span class="o">*=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="k">if</span> <span class="n">units</span> <span class="o">==</span> <span class="s2">&#34;TiB&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="n">size</span> <span class="o">*=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="k">if</span> <span class="n">units</span> <span class="o">==</span> <span class="s2">&#34;EiB&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="c1"># Most probably it is the case when Statistics is unavailable</span>
</span></span><span class="line"><span class="cl">          <span class="c1"># In this case spark just returns max possible value</span>
</span></span><span class="line"><span class="cl">          <span class="c1"># See https://github.com/apache/spark/pull/31817 for details</span>
</span></span><span class="line"><span class="cl">          <span class="n">size</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="k">if</span> <span class="n">size</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="k">return</span> <span class="n">size</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="k">if</span> <span class="n">size_in_mb</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="k">return</span> <span class="n">_bytes2mb</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>  <span class="c1"># size in Mb</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="k">return</span> <span class="n">size</span>  <span class="c1"># size in bytes</span></span></span></code></pre></div>
</div>
</div>
</div>
<div id="outline-container-headline-6" class="outline-3">
<h3 id="headline-6">
Testing
</h3>
<div id="outline-text-headline-6" class="outline-text-3">
<div class="src src-python">
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">  <span class="nb">print</span><span class="p">(</span><span class="n">estimate_size_of_df</span><span class="p">(</span><span class="n">medium_data</span><span class="p">,</span> <span class="n">size_in_mb</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">  <span class="nb">print</span><span class="p">(</span><span class="n">estimate_size_of_df</span><span class="p">(</span><span class="n">medium_data</span><span class="p">,</span> <span class="n">size_in_mb</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">  <span class="nb">print</span><span class="p">(</span><span class="n">estimate_size_of_df</span><span class="p">(</span><span class="n">small_data</span><span class="p">,</span> <span class="n">size_in_mb</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">  <span class="nb">print</span><span class="p">(</span><span class="n">estimate_size_of_df</span><span class="p">(</span><span class="n">tiny_data</span><span class="p">,</span> <span class="n">size_in_mb</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span></span></span></code></pre></div>
</div>
<p>
Result:</p>
<div class="src src-shell">
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">  4831838208.0
</span></span><span class="line"><span class="cl">  4608.0
</span></span><span class="line"><span class="cl">  3.0
</span></span><span class="line"><span class="cl">  1691.0</span></span></code></pre></div>
</div>
</div>
</div>
</div>
</div>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://semyonsinchenko.gihub.io/ssinchenko/tags/spark/">Spark</a></li>
      <li><a href="https://semyonsinchenko.gihub.io/ssinchenko/tags/pyspark/">Pyspark</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://semyonsinchenko.gihub.io/ssinchenko/post/pyspark-column-lineage/">
    <span class="title">« Prev</span>
    <br>
    <span>PySpark column lineage</span>
  </a>
  <a class="next" href="https://semyonsinchenko.gihub.io/ssinchenko/post/cycling-eastern-serbia/">
    <span class="title">Next »</span>
    <br>
    <span>Cycling Eastern Serbia</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share How to estimate a PySpark DF size? on x"
            href="https://x.com/intent/tweet/?text=How%20to%20estimate%20a%20PySpark%20DF%20size%3f&amp;url=https%3a%2f%2fsemyonsinchenko.gihub.io%2fssinchenko%2fpost%2festimation-spark-df-size%2f&amp;hashtags=spark%2cpyspark">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share How to estimate a PySpark DF size? on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fsemyonsinchenko.gihub.io%2fssinchenko%2fpost%2festimation-spark-df-size%2f&amp;title=How%20to%20estimate%20a%20PySpark%20DF%20size%3f&amp;summary=How%20to%20estimate%20a%20PySpark%20DF%20size%3f&amp;source=https%3a%2f%2fsemyonsinchenko.gihub.io%2fssinchenko%2fpost%2festimation-spark-df-size%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share How to estimate a PySpark DF size? on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fsemyonsinchenko.gihub.io%2fssinchenko%2fpost%2festimation-spark-df-size%2f&title=How%20to%20estimate%20a%20PySpark%20DF%20size%3f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share How to estimate a PySpark DF size? on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fsemyonsinchenko.gihub.io%2fssinchenko%2fpost%2festimation-spark-df-size%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share How to estimate a PySpark DF size? on whatsapp"
            href="https://api.whatsapp.com/send?text=How%20to%20estimate%20a%20PySpark%20DF%20size%3f%20-%20https%3a%2f%2fsemyonsinchenko.gihub.io%2fssinchenko%2fpost%2festimation-spark-df-size%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share How to estimate a PySpark DF size? on telegram"
            href="https://telegram.me/share/url?text=How%20to%20estimate%20a%20PySpark%20DF%20size%3f&amp;url=https%3a%2f%2fsemyonsinchenko.gihub.io%2fssinchenko%2fpost%2festimation-spark-df-size%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share How to estimate a PySpark DF size? on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=How%20to%20estimate%20a%20PySpark%20DF%20size%3f&u=https%3a%2f%2fsemyonsinchenko.gihub.io%2fssinchenko%2fpost%2festimation-spark-df-size%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://semyonsinchenko.gihub.io/ssinchenko/">Sem Sinchenko</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
